# 项目简介 (Introduction)

## 背景

AI辅助编译器和代码生成系统正在变得越来越普及。然而，这些系统也面临着后门攻击的威胁。

## 研究目标

本项目旨在研究和开发针对AI辅助编译器中后门攻击的防御机制。

### 主要研究方向

1. **后门攻击检测** - 识别和检测AI模型中的后门
2. **防御机制** - 开发有效的防御策略
3. **安全评估** - 评估AI辅助编译器的安全性

## 相关威胁

- 编译器后门攻击
- LLM模型中的隐写攻击
- 代码生成系统的安全漏洞

## 参考资源

请参阅 `References/` 目录中的学术论文了解更多详情。
